{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "init_notebook_mode(connected = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arff as ar\n",
    "\n",
    "dataset = ar.load(open('data/defect.arff', 'r'))\n",
    "data = np.array(dataset['data'])\n",
    "np.random.shuffle(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "training_data, test_data = np.array_split(data, 2)\n",
    "\n",
    "target_names = np.array(dataset['attributes'][-1][1])\n",
    "\n",
    "split_data = lambda data: (\n",
    "  np.array([e[:-1] for e in data]), \n",
    "  np.array([np.where(target_names == e[-1])[0][0] for e in data]),\n",
    ")\n",
    "\n",
    "training_data, training_target = split_data(training_data)\n",
    "\n",
    "classifier = KMeans(init = 'k-means++', n_clusters = 2, random_state = 0).fit(training_data)\n",
    "\n",
    "test_data, test_target = split_data(test_data)\n",
    "\n",
    "prediction = classifier.predict(test_data)\n",
    "\n",
    "total = len(test_data)\n",
    "correct = (test_target != prediction).sum()\n",
    "\n",
    "print('Number of mislabeled points out of %d points: %d (%.1f%%)' % (\n",
    "  total,\n",
    "  correct,\n",
    "  correct / total * 100.0,\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(test_target, prediction).ravel()\n",
    "\n",
    "iplot({\n",
    "  'data': [go.Pie(\n",
    "    values = [tn, fp, fn, tp],\n",
    "    labels = ['True Negative', 'False Positive', 'False Negative', 'True Positive'],\n",
    "    hole = .4,\n",
    "  )],\n",
    "  'layout': {\n",
    "    'title': 'Confusion Matrix',\n",
    "    'annotations': [{\n",
    "      'font': {'size': 15},\n",
    "      'showarrow': False,\n",
    "      'text': 'KMeans',\n",
    "    }],\n",
    "  },\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace1 = go.Bar(\n",
    "  x = ['Actual Positive'],\n",
    "  y = [fn],\n",
    "  name = 'False Negative',\n",
    ")\n",
    "\n",
    "trace2 = go.Bar(\n",
    "  x = ['Actual Positive'],\n",
    "  y = [tp],\n",
    "  name = 'True Positive',\n",
    ")\n",
    "\n",
    "trace3 = go.Bar(\n",
    "  x = ['Actual Negative'],\n",
    "  y = [tn],\n",
    "  name = 'True Negative',\n",
    ")\n",
    "\n",
    "trace4 = go.Bar(\n",
    "  x = ['Actual Negative'],\n",
    "  y = [fp],\n",
    "  name = 'False Positive',\n",
    ")\n",
    "\n",
    "iplot({\n",
    "  'data': [trace1, trace2, trace3, trace4], \n",
    "  'layout': {\n",
    "    'title': 'Prediction',\n",
    "    'barmode': 'stack',\n",
    "  },\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
