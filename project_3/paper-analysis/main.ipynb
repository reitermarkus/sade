{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import __init__\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!{sys.executable} -m pip install nltk\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('word_tokenize')\n",
    "nltk.download('punkt')\n",
    "\n",
    "import pyLDAvis\n",
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from normalize import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('data/papers.json', 'r', encoding = 'utf-8') as f:\n",
    "  papers = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "titles_df = pd.read_csv('./data/manual_topic_modeling_titles.csv')\n",
    "titles_df.fillna('', inplace = True)\n",
    "titles_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We started by manually labeling the papers and came up with 12 topics, which we then also chose as the number of clusters for the automatic clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import os\n",
    "\n",
    "def build_model(tagged_data):\n",
    "  model = Doc2Vec(\n",
    "    vector_size = 20,\n",
    "    alpha = 0.025, \n",
    "    min_alpha = 0.00025,\n",
    "    min_count = 1,\n",
    "    dm = 1,\n",
    "  )\n",
    "\n",
    "  model.build_vocab(tagged_data)\n",
    "\n",
    "  max_epochs = 100\n",
    "\n",
    "  for epoch in range(max_epochs):\n",
    "    model.train(\n",
    "      tagged_data,\n",
    "      total_examples = model.corpus_count,\n",
    "      epochs = model.epochs,\n",
    "    )\n",
    "    \n",
    "    # decrease the learning rate\n",
    "    model.alpha -= 0.0002\n",
    "    \n",
    "    # fix the learning rate, no decay\n",
    "    model.min_alpha = model.alpha\n",
    "  \n",
    "  return model\n",
    "\n",
    "tagged_titles = [\n",
    "  TaggedDocument(words = clean(paper['title']), tags=[str(paper['id'])]) \n",
    "  for paper in papers\n",
    "]\n",
    "\n",
    "tagged_titles_and_abstracts = [\n",
    "  TaggedDocument(words = clean(paper['title']) + clean(paper['abstract']), tags=[str(paper['id'])]) \n",
    "  for paper in papers\n",
    "]\n",
    "  \n",
    "title_model = build_model(tagged_titles)\n",
    "title_and_abstract_model = build_model(tagged_titles_and_abstracts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "init_notebook_mode(connected = True)\n",
    "\n",
    "def generate_prediction(model, n_clusters = 12):\n",
    "  return KMeans(init = 'k-means++', n_clusters = n_clusters).fit(model.docvecs.vectors_docs)\n",
    "\n",
    "def plot_cluster_table(model, kmeans):\n",
    "  trace = go.Table(\n",
    "    header = dict(values = ['Document ID', 'Cluster ID']),\n",
    "    cells = dict(values = [model.docvecs.offset2doctag, kmeans.labels_]),\n",
    "  )\n",
    "\n",
    "  data = [trace]\n",
    "\n",
    "  figure = go.Figure(data = data)\n",
    "\n",
    "  return iplot(figure)\n",
    "\n",
    "title_kmeans = generate_prediction(title_model)\n",
    "title_and_abstract_kmeans = generate_prediction(title_and_abstract_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_cluster_table(title_model, title_kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_cluster_table(title_and_abstract_model, title_and_abstract_kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mapping_dict(model, kmeans):\n",
    "  import numpy as np\n",
    "  return dict(zip(np.int64(model.docvecs.offset2doctag), kmeans.labels_))\n",
    "\n",
    "title_cluster_mapping = create_mapping_dict(title_model, title_kmeans)\n",
    "title_and_abstract_cluster_mapping = create_mapping_dict(title_and_abstract_model, title_and_abstract_kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def find_most_similar_vectors(tagged_data, similar_to, model_name, create_model=False, topn=5):\n",
    "  # similar_to: tag (int) or text\n",
    "\n",
    "  if create_model:\n",
    "    create_and_train(tagged_abstracts, model_name)\n",
    "  \n",
    "  model = Doc2Vec.load(f'data/{model_name}')\n",
    "\n",
    "  if isinstance(similar_to, int):\n",
    "    pass\n",
    "  elif isinstance(similar_to, str):\n",
    "    similar_to = [model.infer_vector(word_tokenize(similar_to))]\n",
    "  \n",
    "  similar_vectors = model.docvecs.most_similar(similar_to, topn = topn)\n",
    "    \n",
    "  result = [(tag, value) for tag, value in similar_vectors]\n",
    "\n",
    "  return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Example Most Similar Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_check = 'A Domain Specific Language based on Monads for Distributed Transactional Memory in Java'\n",
    "cmp_string = find_most_similar_vectors(tagged_titles, to_check, 'title.model', topn = 10, create_model = False)\n",
    "cmp_tag = find_most_similar_vectors(tagged_titles, 1, 'title.model', topn = 10, create_model = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from topic_modeling import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "create_dir('./data/topic_modeling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def papers_topic_modeling(tagged_data, field_name):\n",
    "  words = [t.words for t in tagged_data]\n",
    "  return compute_lda_model(f'./data/topic_modeling/{field_name}', words)\n",
    "  \n",
    "def display_topic_modeling(field_name):\n",
    "  return display_lda_model(f'./data/topic_modeling/{field_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "title_model = papers_topic_modeling(tagged_titles, 'title')\n",
    "pyLDAvis.display(display_topic_modeling('title'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "title_and_abstract_model = papers_topic_modeling(tagged_titles_and_abstracts, 'title_and_abstract')\n",
    "pyLDAvis.display(display_topic_modeling('title_and_abstract'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy of automated topic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(tagged_data, field_name, manual_topics):\n",
    "  def is_in_manual_topics(t):\n",
    "    for i in manual_topics:\n",
    "      topic = i.lower()\n",
    "      topic = topic.replace('&', '')\n",
    "      topic = list(filter(None, topic.split(' ')))\n",
    "      \n",
    "      if t in topic:\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "      \n",
    "  accuracy = []\n",
    "  \n",
    "  for _ in range(10):\n",
    "    tmp = 0\n",
    "    title_model = papers_topic_modeling(tagged_data, field_name)\n",
    "\n",
    "    topic_1 = title_model.show_topic(0, 12)\n",
    "    topic_2 = title_model.show_topic(1, 12)\n",
    "    topics = set(topic_1).union(topic_2)\n",
    "    \n",
    "    for t in topics:\n",
    "      if is_in_manual_topics(t[0]):\n",
    "        tmp += 1\n",
    "    \n",
    "    accuracy.append(tmp)\n",
    "  \n",
    "  return (np.mean(accuracy) / 10) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "accuracy = compute_accuracy(tagged_titles, 'title', titles_df.columns)\n",
    "print(f'Accuracy of automated topic modeling for titles: {round(accuracy, 4)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic modeling for the topics of  the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_topic_modeling(data, cluster_id, field_name):\n",
    "  return compute_lda_model(f'./data/topic_modeling/clusters/{cluster_id}', data)\n",
    "\n",
    "def get_topics_of_cluster(cluster):\n",
    "  return [t[field_name] for t in papers if t['id'] == cluster]\n",
    "\n",
    "def topic_modeling_for_cluster_topics(topic_cluster_mapping, field_name):\n",
    "  clusters = np.unique([topic_cluster_mapping[t] for t in topic_cluster_mapping])\n",
    "  cluster_topic_obj = {}\n",
    "  \n",
    "  for t in topic_cluster_mapping:\n",
    "    cluster_topic_obj.setdefault(topic_cluster_mapping[t],[]).append(t)\n",
    "\n",
    "  res = []\n",
    "  \n",
    "  for c in cluster_topic_obj:\n",
    "    topic_ids = cluster_topic_obj[c]\n",
    "    data = [clean(papers[t][field_name]) for t in topic_ids]\n",
    "    res.append(compute_lda_model(f'./data/topic_modeling/clusters/{c}', data))\n",
    "  \n",
    "  return res\n",
    "    \n",
    "title_clusters_topic_modeling = topic_modeling_for_cluster_topics(title_cluster_mapping, 'title')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot topics of a cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.display(display_topic_modeling('clusters/3'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
